\chapter{Conclusions}
The AK-MCS algorithm proved to have several advantages, being a substantial
improvement of the basic MCS method. It retains the advantages of the latter,
improving its main disadvantage which is having to call the expensive performance
function so many times. This improvement becomes more evident as the complexity of the performance function increases.\\

The choice of one learning function over another should be influenced by the
nature and form of the problem. Although they are all based on the same parameters,
the manner in which they determine the evolution of the prediction process varies
by giving greater importance to different aspects of the design space and the performance
function. Likewise, the choice of thresholds for the stopping conditions is of great importance,
as they represent the usual trade-off between cost and benefit. It could be seen that in
the worked examples, the suggested threshold of the learning function H was too high,
yet for some particular problems it was low enough. \\

Given the simplicity of the nature of the method, its potential for improvement
is very high. In principle, the formulation of new learning functions is a
boundless task. Moreover, different ways of approaching the problem following the
same principles have been studied. For example, in \citep{Peijuan2017} geometrical considerations
are presented that allow to improve the efficiency of the method, although limiting
its applicability. In \citep{Balesdent2013} work is done on a variant of the crude MCS. And as well
as these, there are many modifications that are pending to be studied, and even
proposed, that could further improve the qualities of the method. \\

Regarding the proposed objectives, the MCS method, its formulation and main characteristics were studied, as well as the kriging algorithm, after having made a contextualization in the field of reliability analysis to determine failure probabilities. The article \citep{Echard2011} was studied in its entirety, and several examples were implemented, comparing the results given by AK-MCS with those obtained with MCS. \\

For future work, one can study new learning functions, and try to categorize them according to the type of problems for which each is most appropriate. The application of active learning methods combined with variations to the basic MCS algorithm could also be studied. The use of different kernels to define the covariance function is also an important field of study that is continually developing, so a review of these can be considered.